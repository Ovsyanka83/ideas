Tokenize notebook
=================

.. code:: ipython3

    from ideas import token_utils

.. code:: ipython3

    source = "a = a"
    tokens = token_utils.tokenize(source)
    for token in tokens:
        print(token)


.. parsed-literal::

    type=1 (NAME)  string='a'  start=(1, 0)  end=(1, 1)  line='a = a'
    type=53 (OP)  string='='  start=(1, 2)  end=(1, 3)  line='a = a'
    type=1 (NAME)  string='a'  start=(1, 4)  end=(1, 5)  line='a = a'
    type=4 (NEWLINE)  string=''  start=(1, 5)  end=(1, 6)  line=''
    type=0 (ENDMARKER)  string=''  start=(2, 0)  end=(2, 0)  line=''

