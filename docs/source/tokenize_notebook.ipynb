{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing notebook\n",
    "\n",
    "Here, we demonstrate some usage of the tokenizing utility functions.\n",
    "The content is in two main sections. First, we demonstrate the\n",
    "usage of various functions to get information. Once this is\n",
    "done, we demonstrate how to change the content in a reliable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ideas import token_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting information\n",
    "We start with a very simple example, where we have a repeated token, `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type=1 (NAME)  string='a'  start=(1, 0)  end=(1, 1)  line='a = a'\n",
      "type=53 (OP)  string='='  start=(1, 2)  end=(1, 3)  line='a = a'\n",
      "type=1 (NAME)  string='a'  start=(1, 4)  end=(1, 5)  line='a = a'\n",
      "type=4 (NEWLINE)  string=''  start=(1, 5)  end=(1, 6)  line=''\n",
      "type=0 (ENDMARKER)  string=''  start=(2, 0)  end=(2, 0)  line=''\n"
     ]
    }
   ],
   "source": [
    "source = \"a = a\"\n",
    "tokens = token_utils.tokenize(source)\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the `NEWLINE` token here, in spite of its name, does not correpond to `\\n`.\n",
    "\n",
    "### Comparing tokens\n",
    "\n",
    "Tokens are considered equals if they have the same `string` attribute. Given this notion of equality, we make things even simpler by allowing to compare a token directly to a string as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tokens[0] == tokens[2])\n",
    "print(tokens[0] == tokens[2].string)\n",
    "print(tokens[0] == 'a')  #  <--  Our normal choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing tokens by line of code\n",
    "If we simply want to tokenize a source and print the result, or simply print a list of tokens, we can use `print_tokens` to do it in a single instruction, with the added benefit of separating tokens from different lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type=56 (NL)  string='\\n'  start=(1, 0)  end=(1, 1)  line='\\n'\n",
      "\n",
      "type=1 (NAME)  string='if'  start=(2, 0)  end=(2, 2)  line='if True:\\n'\n",
      "type=1 (NAME)  string='True'  start=(2, 3)  end=(2, 7)  line='if True:\\n'\n",
      "type=53 (OP)  string=':'  start=(2, 7)  end=(2, 8)  line='if True:\\n'\n",
      "type=4 (NEWLINE)  string='\\n'  start=(2, 8)  end=(2, 9)  line='if True:\\n'\n",
      "\n",
      "type=5 (INDENT)  string='    '  start=(3, 0)  end=(3, 4)  line='    pass\\n'\n",
      "type=1 (NAME)  string='pass'  start=(3, 4)  end=(3, 8)  line='    pass\\n'\n",
      "type=4 (NEWLINE)  string='\\n'  start=(3, 8)  end=(3, 9)  line='    pass\\n'\n",
      "\n",
      "type=6 (DEDENT)  string=''  start=(4, 0)  end=(4, 0)  line=''\n",
      "type=0 (ENDMARKER)  string=''  start=(4, 0)  end=(4, 0)  line=''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = \"\"\"\n",
    "if True:\n",
    "    pass\n",
    "\"\"\"\n",
    "token_utils.print_tokens(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting tokens by line of code\n",
    "Once a source is broken down into token, it might be difficult to find some particular tokens of interest if we print the entire content. Instead, using `get_lines`, we can tokenize by line of code , and just focus on a few lines of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type=6 (DEDENT)  string=''  start=(5, 4)  end=(5, 4)  line='    else:\\n'\n",
      "type=1 (NAME)  string='else'  start=(5, 4)  end=(5, 8)  line='    else:\\n'\n",
      "type=53 (OP)  string=':'  start=(5, 8)  end=(5, 9)  line='    else:\\n'\n",
      "type=4 (NEWLINE)  string='\\n'  start=(5, 9)  end=(5, 10)  line='    else:\\n'\n",
      "\n",
      "type=5 (INDENT)  string='        '  start=(6, 0)  end=(6, 8)  line='        a = 42 # a comment\\n'\n",
      "type=1 (NAME)  string='a'  start=(6, 8)  end=(6, 9)  line='        a = 42 # a comment\\n'\n",
      "type=53 (OP)  string='='  start=(6, 10)  end=(6, 11)  line='        a = 42 # a comment\\n'\n",
      "type=2 (NUMBER)  string='42'  start=(6, 12)  end=(6, 14)  line='        a = 42 # a comment\\n'\n",
      "type=55 (COMMENT)  string='# a comment'  start=(6, 15)  end=(6, 26)  line='        a = 42 # a comment\\n'\n",
      "type=4 (NEWLINE)  string='\\n'  start=(6, 26)  end=(6, 27)  line='        a = 42 # a comment\\n'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = \"\"\"\n",
    "if True:\n",
    "    if False:\n",
    "        pass\n",
    "    else:\n",
    "        a = 42 # a comment\n",
    "print('ok')\n",
    "\"\"\"\n",
    "lines = token_utils.get_lines(source)\n",
    "for line in lines[4:6]:\n",
    "    for token in line:\n",
    "        print(token)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting particular tokens\n",
    "Let's focus on the sixth line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a = 1 # a comment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "line = lines[5]\n",
    "print( token_utils.untokenize(line) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignoring the indentation, the first token is `a`; ignoring newlines indicator and comments, the last token is `1`. We can get at these tokens using some utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first useful token is:\n",
      "    type=1 (NAME)  string='a'  start=(6, 8)  end=(6, 9)  line='        a = 1 # a comment\\n'\n",
      "The index of the first token is:  1\n",
      "\n",
      "The last useful token on that line is:\n",
      "   type=2 (NUMBER)  string='1'  start=(6, 12)  end=(6, 13)  line='        a = 1 # a comment\\n'\n",
      "Its index is 2\n"
     ]
    }
   ],
   "source": [
    "print(\"The first useful token is:\\n   \", token_utils.get_first(line))\n",
    "print(\"The index of the first token is: \", token_utils.get_first_index(line))\n",
    "print()\n",
    "print(\"The last useful token on that line is:\\n  \", token_utils.get_last(line))\n",
    "print(\"Its index is\", token_utils.get_last_index(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these four functions, `get_first`, `get_first_index`, `get_last`, `get_last_index` exclude end of line comments by default; but this can be changed by setting the optional parameter `exclude_comment` to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type=55 (COMMENT)  string='# a comment'  start=(6, 14)  end=(6, 25)  line='        a = 1 # a comment\\n'\n"
     ]
    }
   ],
   "source": [
    "print( token_utils.get_last(line, exclude_comment=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the indentation of a line\n",
    "This particular line starts with an `INDENT` token. We can get the indentation of that line, either by printing the length of the `INDENT` token string, or by looking at the `start_col` attribute of the first \"useful\" token. The attribute `start_col` is part of the two-tuple `start = (start_row, start_col)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(line[0].string))\n",
    "first = token_utils.get_first(line)\n",
    "print(first.start_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, **the second method is more reliable**. For example, if we look at tokens the previous line (line 5, index 4), we can see that the length of the string of the first token, `INDENT`, does not give us the information about the line indentation. Furthermore, a given line may start with multiple `INDENT` tokens. However, once again, the `start_col` attribute of the first \"useful\" token can give us this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type=6 (DEDENT)  string=''  start=(5, 4)  end=(5, 4)  line='    else:\\n'\n",
      "type=1 (NAME)  string='else'  start=(5, 4)  end=(5, 8)  line='    else:\\n'\n",
      "type=53 (OP)  string=':'  start=(5, 8)  end=(5, 9)  line='    else:\\n'\n",
      "type=4 (NEWLINE)  string='\\n'  start=(5, 9)  end=(5, 10)  line='    else:\\n'\n",
      "--------------------------------------------------\n",
      "    else:\n",
      "\n",
      "indentation =  4\n"
     ]
    }
   ],
   "source": [
    "for token in lines[4]:\n",
    "    print(token)\n",
    "print(\"-\" * 50)\n",
    "    \n",
    "print(token_utils.untokenize(lines[4]))\n",
    "first = token_utils.get_first(lines[4])\n",
    "print(\"indentation = \", first.start_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
